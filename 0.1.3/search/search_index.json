{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ProxyStore Extensions","text":"<p>Extensions for the ProxyStore package.</p> <p>This extensions package contains experimental features, features with non-Python dependencies, and plugins for third-party tools.</p>"},{"location":"#installation","title":"Installation","text":"<p>The extensions package can be installed alongside ProxyStore. <pre><code>$ pip install proxystore[extensions]\n</code></pre></p> <p>Alternatively, the package can be installed directly. <pre><code>$ pip install proxystore-ex\n</code></pre></p> <p>See the Installation guide for more information about features which require extra dependencies. See the Contributing guide to get started with local development.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>ProxyStore's documentation is available at docs.proxystore.dev and supplemental documentation for the extensions package is available at extensions.proxystore.dev.</p>"},{"location":"#usage","title":"Usage","text":"<p>Features in the <code>proxystore_ex</code> package can be imported from within <code>proxystore</code> via the <code>proxystore.ex</code> module. This is the recommended method for import extension features. E.g.,</p> <pre><code>from proxystore_ex.connectors.daos import DAOSConnector  # Direct\nfrom proxystore.ex.connectors.daos import DAOSConnector  # Recommended\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>The preferred citations for this code are provided at https://docs.proxystore.dev/latest/publications/.</p>"},{"location":"installation/","title":"Installation","text":"<p>ProxyStore Extensions should be installed alongside ProxyStore. <pre><code>$ pip install proxystore[extensions]\n</code></pre> Checkout ProxyStore's Installation Guide for more details.</p> <p>Note</p> <p>ProxyStore Extensions can be installed directly. <pre><code>$ pip install proxystore-ex\n</code></pre> This is generally not recommended because this will install the base ProxyStore package if it is not installed already. This means that none of the extra options from ProxyStore that you may need will be installed. See the ProxyStore Installation Guide for how to install the base ProxyStore package with extra options.</p>"},{"location":"installation/#distributed-in-memory-connectors","title":"Distributed In-Memory Connectors","text":"<p>The <code>MargoConnector</code> and <code>UCXConnector</code> have additional manual installation steps to be completed before they can be used. These steps are reasonably involved and may change over time so checkout the following resources for the most up-to-date instructions.</p> <ul> <li>Margo:<ul> <li>Install Mochi-Margo and the dependencies</li> <li>Install Py-Mochi-Margo</li> </ul> </li> <li>UCX:<ul> <li>Install UCX</li> <li>Install UCX-Py</li> </ul> </li> </ul>"},{"location":"api/","title":"proxystore_ex","text":"<code>proxystore_ex/__init__.py</code> <p>Extensions for ProxyStore.</p> <p>Tip</p> <p>Extension features can be imported directly. E.g., <pre><code>from proxystore_ex.connectors.daos import DAOSConnector\n</code></pre> But we recommend replacing <code>proxystore_ex</code> with <code>proxystore.ex</code>. E.g., <pre><code>from proxystore.ex.connectors.daos import DAOSConnector\n</code></pre></p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>proxystore_ex</li> <li>proxystore_ex.connectors<ul> <li>daos</li> <li>dim<ul> <li>exceptions</li> <li>margo</li> <li>models</li> <li>ucx</li> <li>utils</li> <li>zmq</li> </ul> </li> </ul> </li> <li>proxystore_ex.plugins<ul> <li>distributed</li> </ul> </li> </ul>"},{"location":"api/connectors/","title":"proxystore_ex.connectors","text":"<code>proxystore_ex/connectors/__init__.py</code> <p>Connector implementations.</p> <p>This is an extension of the <code>proxystore.connectors</code> module.</p>"},{"location":"api/connectors/daos/","title":"proxystore_ex.connectors.daos","text":"<code>proxystore_ex/connectors/daos.py</code> <p>DAOS Container connector implementation.</p>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSKey","title":"DAOSKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to object stored in a DAOS container.</p> <p>Attributes:</p> <ul> <li> <code>pool</code>             (<code>str</code>)         \u2013          <p>DAOS pool the container belongs to.</p> </li> <li> <code>container</code>             (<code>str</code>)         \u2013          <p>Name of the DAOS container the dictionary with the object is in.</p> </li> <li> <code>namespace</code>             (<code>str</code>)         \u2013          <p>Name of the DAOS dictionary the object is in.</p> </li> <li> <code>dict_key</code>             (<code>str</code>)         \u2013          <p>Unique key in the DAOS dictionary.</p> </li> </ul>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector","title":"DAOSConnector","text":"<pre><code>DAOSConnector(\n    pool: str,\n    container: str,\n    namespace: str,\n    clear: bool = False,\n)\n</code></pre> <p>DAOS Container connector.</p> <p>Learn more about DAOS in Python here.</p> Example <p>Assume we have a DAOS pool named \"mypool.\" First, we create a new container in that pool named \"kvstore\" with type <code>PYTHON</code>.</p> <pre><code>$ daos cont create mypool --type=PYTHON --label=kvstore\n</code></pre> <p>Then we can create a connector. <pre><code>from proxystore_ex.connectors.daos import DAOSConnector\n\nwith DAOSConnector('mypool', 'kvstore', 'mynamespace') as connector:\n    key = connector.put('value')\n    assert connector.get(key) == 'value'\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>pool</code>             (<code>str</code>)         \u2013          <p>DAOS pool label or UUID string.</p> </li> <li> <code>container</code>             (<code>str</code>)         \u2013          <p>DAOS container label or UUID string.</p> </li> <li> <code>namespace</code>             (<code>str</code>)         \u2013          <p>Name of the DAOS dictionary created in the DAOS container. All operations will be performed on this one dictionary so it can be thought of as a logically namespace separated from other applications interacting with this DAOS container.</p> </li> <li> <code>clear</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Remove all keys from the DAOS dictionary named <code>namespace</code> when <code>close()</code> is called. This will delete keys regardless of if they were created by ProxyStore or not.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def __init__(\n    self,\n    pool: str,\n    container: str,\n    namespace: str,\n    clear: bool = False,\n) -&gt; None:\n    self.pool = pool\n    self.container = container\n    self.namespace = namespace\n    self.clear = clear\n\n    self._container = pydaos.DCont(self.pool, self.container)\n    try:\n        self._dict = self._container.get(self.namespace)\n    except pydaos.DObjNotFound:\n        self._dict = self._container.dict(self.namespace)\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.close","title":"close()","text":"<pre><code>close(clear: bool | None = None) -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Warning <p>Passing <code>clear=True</code> will result in ALL keys in the DAOS Dictionary being deleted regardless of if they were created by ProxyStore or not.</p> <p>Parameters:</p> <ul> <li> <code>clear</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Remove all keys in the DAOS dictionary. Overrides the default value of <code>clear</code> provided when the <code>DAOSConnector</code> was instantiated.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def close(self, clear: bool | None = None) -&gt; None:\n    \"\"\"Close the connector and clean up.\n\n    Warning:\n        Passing `clear=True` will result in **ALL** keys in the DAOS\n        Dictionary being deleted regardless of if they were created by\n        ProxyStore or not.\n\n    Args:\n        clear: Remove all keys in the DAOS dictionary. Overrides the\n            default value of `clear` provided when the\n            [`DAOSConnector`][proxystore_ex.connectors.daos.DAOSConnector]\n            was instantiated.\n    \"\"\"\n    if self.clear if clear is None else clear:\n        for key in list(self._dict):\n            del self._dict[key]\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'pool': self.pool,\n        'container': self.container,\n        'namespace': self.namespace,\n        'clear': self.clear,\n    }\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; DAOSConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; DAOSConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.evict","title":"evict()","text":"<pre><code>evict(key: DAOSKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DAOSKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def evict(self, key: DAOSKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    self._validate_key(key)\n    self._dict.pop(key.dict_key)\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.exists","title":"exists()","text":"<pre><code>exists(key: DAOSKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DAOSKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def exists(self, key: DAOSKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    self._validate_key(key)\n    return key.dict_key in self._dict\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.get","title":"get()","text":"<pre><code>get(key: DAOSKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DAOSKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def get(self, key: DAOSKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    self._validate_key(key)\n    try:\n        return self._dict.get(key.dict_key)\n    except KeyError:\n        return None\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[DAOSKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[DAOSKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def get_batch(self, keys: Sequence[DAOSKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    # Note: using DDict.bget() would be more efficient, but it will\n    # error if any key is missing. So to maintain the semantics of\n    # this method, we have to try each key individually.\n    objs: list[bytes | None] = []\n    for key in keys:\n        self._validate_key(key)\n        objs.append(self.get(key))\n    return objs\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.new_key","title":"new_key()","text":"<pre><code>new_key(obj: bytes | None = None) -&gt; DAOSKey\n</code></pre> <p>Create a new key.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional object which the key will be associated with. Ignored in this implementation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DAOSKey</code>         \u2013          <p>Key which can be used to retrieve an object once             <code>set()</code>             has been called on the key.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def new_key(self, obj: bytes | None = None) -&gt; DAOSKey:\n    \"\"\"Create a new key.\n\n    Args:\n        obj: Optional object which the key will be associated with.\n            Ignored in this implementation.\n\n    Returns:\n        Key which can be used to retrieve an object once \\\n        [`set()`][proxystore_ex.connectors.daos.DAOSConnector.set] \\\n        has been called on the key.\n    \"\"\"\n    return DAOSKey(\n        pool=self.pool,\n        container=self.container,\n        namespace=self.namespace,\n        dict_key=str(uuid.uuid4()),\n    )\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; DAOSKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DAOSKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def put(self, obj: bytes) -&gt; DAOSKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = DAOSKey(\n        pool=self.pool,\n        container=self.container,\n        namespace=self.namespace,\n        dict_key=str(uuid.uuid4()),\n    )\n    self._dict.put(key.dict_key, obj)\n    return key\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[DAOSKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[DAOSKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[DAOSKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    keys = [\n        DAOSKey(\n            pool=self.pool,\n            container=self.container,\n            namespace=self.namespace,\n            dict_key=str(uuid.uuid4()),\n        )\n        for _ in objs\n    ]\n    self._dict.bput({key.dict_key: obj for key, obj in zip(keys, objs)})\n    return keys\n</code></pre>"},{"location":"api/connectors/daos/#proxystore_ex.connectors.daos.DAOSConnector.set","title":"set()","text":"<pre><code>set(key: DAOSKey, obj: bytes) -&gt; None\n</code></pre> <p>Set the object associated with a key.</p> Note <p>The <code>Connector</code> provides write-once, read-many semantics. Thus, <code>set()</code> should only be called once per key, otherwise unexpected behavior can occur.</p> Warning <p>This method is not required to be atomic and could therefore result in race conditions with calls to <code>get()</code>.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DAOSKey</code>)         \u2013          <p>Key that the object will be associated with.</p> </li> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Object to associate with the key.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/daos.py</code> <pre><code>def set(self, key: DAOSKey, obj: bytes) -&gt; None:\n    \"\"\"Set the object associated with a key.\n\n    Note:\n        The [`Connector`][proxystore.connectors.protocols.Connector]\n        provides write-once, read-many semantics. Thus,\n        [`set()`][proxystore.connectors.protocols.DeferrableConnector.set]\n        should only be called once per key, otherwise unexpected behavior\n        can occur.\n\n    Warning:\n        This method is not required to be atomic and could therefore\n        result in race conditions with calls to\n        [`get()`][proxystore.connectors.protocols.Connector.get].\n\n    Args:\n        key: Key that the object will be associated with.\n        obj: Object to associate with the key.\n    \"\"\"\n    self._dict.put(key.dict_key, obj)\n</code></pre>"},{"location":"api/connectors/dim/","title":"proxystore_ex.connectors.dim","text":"<code>proxystore_ex/connectors/dim/__init__.py</code> <p>Distributed in-memory store connectors.</p>"},{"location":"api/connectors/dim/exceptions/","title":"proxystore_ex.connectors.dim.exceptions","text":"<code>proxystore_ex/connectors/dim/exceptions.py</code> <p>Exception types.</p>"},{"location":"api/connectors/dim/exceptions/#proxystore_ex.connectors.dim.exceptions.ServerTimeoutError","title":"ServerTimeoutError","text":"<p>             Bases: <code>Exception</code></p> <p>Error indicating client timed out while trying to connect to server.</p>"},{"location":"api/connectors/dim/margo/","title":"proxystore_ex.connectors.dim.margo","text":"<code>proxystore_ex/connectors/dim/margo.py</code> <p>Margo RPC-based distributed in-memory connector implementation.</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol","title":"Protocol","text":"<p>             Bases: <code>Enum</code></p> <p>Available Mercury plugins and transports.</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.OFI_TCP","title":"OFI_TCP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OFI_TCP = 'ofi+tcp'\n</code></pre> <p>libfabric tcp provider (TCP/IP)</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.OFI_VERBS","title":"OFI_VERBS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OFI_VERBS = 'ofi+verbs'\n</code></pre> <p>libfabric Verbs provider (InfiniBand or RoCE)</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.OFI_GNI","title":"OFI_GNI  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OFI_GNI = 'ofi+gni'\n</code></pre> <p>libfabric GNI provider (Cray Aries)</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.UCX_TCP","title":"UCX_TCP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UCX_TCP = 'ucx+tcp'\n</code></pre> <p>UCX TCP/IP</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.UCX_VERBS","title":"UCX_VERBS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UCX_VERBS = 'ucx+verbs'\n</code></pre> <p>UCX Verbs</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.SM_SHM","title":"SM_SHM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SM_SHM = 'sm+shm'\n</code></pre> <p>Shared memory shm</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.Protocol.BMI_TCP","title":"BMI_TCP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BMI_TCP = 'bmi+tcp'\n</code></pre> <p>BMI tcp module (TCP/IP)</p>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector","title":"MargoConnector","text":"<pre><code>MargoConnector(\n    port: int,\n    protocol: Protocol | str,\n    address: str | None = None,\n    interface: str | None = None,\n    timeout: float = 1,\n    force_spawn_server: bool = False,\n)\n</code></pre> <p>Margo RPC-based distributed in-memory connector.</p> Note <p>The first instance of this connector created on a process will spawn a <code>MargoServer</code> that will store data. Hence, this connector just acts as an interface to that server.</p> <p>Parameters:</p> <ul> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>The desired port for the spawned server.</p> </li> <li> <code>protocol</code>             (<code>Protocol | str</code>)         \u2013          <p>The communication protocol to use.</p> </li> <li> <code>address</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>The network IP to use for transfer. Has precedence over <code>interface</code> if both are provided.</p> </li> <li> <code>interface</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>The network interface to use. <code>addr</code> has precedence over this attribute if both are provided.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Timeout in seconds to try connecting to a local server before spawning one.</p> </li> <li> <code>force_spawn_server</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Force spawn a server rather than waiting to check if one is already running.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If a local server cannot be connected to within <code>timeout</code> seconds, and a new local server does not respond within <code>timeout</code> seconds after being started.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def __init__(\n    self,\n    port: int,\n    protocol: Protocol | str,\n    address: str | None = None,\n    interface: str | None = None,\n    timeout: float = 1,\n    force_spawn_server: bool = False,\n) -&gt; None:\n    # Py-Mochi-Margo is not a required dependency and requires the user\n    # to install it themselves.\n    if pymargo_import_error is not None:  # pragma: no cover\n        raise pymargo_import_error\n\n    self._address = address\n    self._interface = interface\n    self.port = port\n    self.protocol = (\n        protocol if isinstance(protocol, str) else protocol.value\n    )\n\n    self.timeout = timeout\n    self.force_spawn_server = force_spawn_server\n\n    self.engine = Engine(\n        self.protocol,\n        mode=pymargo.client,\n        use_progress_thread=True,\n    )\n\n    if self._address is not None:\n        self.address = self._address\n    elif self._interface is not None:  # pragma: darwin no cover\n        self.address = get_ip_address(self._interface)\n    else:\n        eng_url = str(self.engine.addr())\n        self.address = eng_url.split(':')[1].split('/')[2]\n\n    self.url = f'{self.protocol}://{self.address}:{self.port}'\n\n    self._rpcs = {\n        'evict': self.engine.register('evict'),\n        'exists': self.engine.register('exists'),\n        'get': self.engine.register('get'),\n        'put': self.engine.register('put'),\n    }\n\n    server_available = False\n    if not force_spawn_server:\n        try:\n            logger.info(\n                f'Connecting to local server (address={self.url})...',\n            )\n            wait_for_server(\n                self.protocol,\n                self.address,\n                self.port,\n                self.timeout,\n            )\n            logger.info(\n                f'Connected to local server (address={self.url})',\n            )\n            server_available = True\n        except ServerTimeoutError:\n            logger.info(\n                'Failed to connect to local server '\n                f'(address={self.url}, timeout={self.timeout})',\n            )\n\n    self.server: multiprocessing.context.SpawnProcess | None\n    if not server_available or force_spawn_server:\n        self.server = spawn_server(\n            self.protocol,\n            self.address,\n            self.port,\n            spawn_timeout=self.timeout,\n        )\n        logger.info(f'Spawned local server (address={self.url})')\n    else:\n        self.server = None\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.close","title":"close()","text":"<pre><code>close(kill_server: bool = True) -&gt; None\n</code></pre> <p>Close the connector.</p> <p>Parameters:</p> <ul> <li> <code>kill_server</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to kill the server process. If this instance did not spawn the local node's server process, this is a no-op.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def close(self, kill_server: bool = True) -&gt; None:\n    \"\"\"Close the connector.\n\n    Args:\n        kill_server: Whether to kill the server process. If this instance\n            did not spawn the local node's server process, this is a\n            no-op.\n    \"\"\"\n    if kill_server and self.server is not None:\n        self.engine.lookup(self.url).shutdown()\n        self.server.join()\n        logger.info(\n            'Terminated local server on connector close '\n            f'(pid={self.server.pid})',\n        )\n\n    self.engine.finalize()\n    logger.info('Closed Margo connector')\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'address': self._address,\n        'interface': self._interface,\n        'port': self.port,\n        'protocol': self.protocol,\n        'timeout': self.timeout,\n        'force_spawn_server': self.force_spawn_server,\n    }\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; MargoConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; MargoConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.evict","title":"evict()","text":"<pre><code>evict(key: DIMKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def evict(self, key: DIMKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    rpc = RPC(operation='evict', key=key)\n    self._send_rpcs([rpc])\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.exists","title":"exists()","text":"<pre><code>exists(key: DIMKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def exists(self, key: DIMKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    rpc = RPC(operation='exists', key=key)\n    (response,) = self._send_rpcs([rpc])\n    assert response.exists is not None\n    return response.exists\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.get","title":"get()","text":"<pre><code>get(key: DIMKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def get(self, key: DIMKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    buff = bytearray(key.size)\n    blk = self.engine.create_bulk(buff, bulk.write_only)\n\n    rpc = RPC(operation='get', key=key, data=blk)\n    (result,) = self._send_rpcs([rpc])\n\n    if result.exists:\n        return bytes(buff)\n\n    return None\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[DIMKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[DIMKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def get_batch(self, keys: Sequence[DIMKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    rpcs: list[RPC] = []\n    buffers: list[bytearray] = []\n\n    for key in keys:\n        buff = bytearray(key.size)\n        blk = self.engine.create_bulk(buff, bulk.write_only)\n\n        buffers.append(buff)\n        rpcs.append(RPC(operation='get', key=key, data=blk))\n\n    responses = self._send_rpcs(rpcs)\n    return [\n        bytes(b) if responses[i].exists else None\n        for i, b in enumerate(buffers)\n    ]\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; DIMKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DIMKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def put(self, obj: bytes) -&gt; DIMKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = DIMKey(\n        dim_type='margo',\n        obj_id=str(uuid.uuid4()),\n        size=len(obj),\n        peer_host=self.address,\n        peer_port=self.port,\n    )\n    blk = self.engine.create_bulk(obj, bulk.read_only)\n\n    rpc = RPC(operation='put', key=key, data=blk)\n    self._send_rpcs([rpc])\n    return key\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[DIMKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[DIMKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[DIMKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    keys = [\n        DIMKey(\n            dim_type='margo',\n            obj_id=str(uuid.uuid4()),\n            size=len(obj),\n            peer_host=self.address,\n            peer_port=self.port,\n        )\n        for obj in objs\n    ]\n    rpcs: list[RPC] = []\n\n    for key, obj in zip(keys, objs):\n        blk = self.engine.create_bulk(obj, bulk.read_only)\n        rpcs.append(RPC(operation='put', key=key, data=blk))\n\n    self._send_rpcs(rpcs)\n\n    return keys\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoServer","title":"MargoServer","text":"<pre><code>MargoServer(engine: Engine)\n</code></pre> <p>MargoServer implementation.</p> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def __init__(self, engine: Engine) -&gt; None:\n    self.data: dict[str, bytes] = {}\n    self.engine = engine\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoServer.evict","title":"evict()","text":"<pre><code>evict(\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None\n</code></pre> <p>Remove key from local dictionary.</p> <p>Parameters:</p> <ul> <li> <code>handle</code>             (<code>Handle</code>)         \u2013          <p>The client handle.</p> </li> <li> <code>bulk_str</code>             (<code>Bulk</code>)         \u2013          <p>The buffer that will store shared data.</p> </li> <li> <code>bulk_size</code>             (<code>int</code>)         \u2013          <p>The size of the data to be received.</p> </li> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>The data's key.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def evict(\n    self,\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None:\n    \"\"\"Remove key from local dictionary.\n\n    Args:\n        handle: The client handle.\n        bulk_str: The buffer that will store shared data.\n        bulk_size: The size of the data to be received.\n        key: The data's key.\n    \"\"\"\n    self.data.pop(key.obj_id, None)\n    response = RPCResponse(operation='evict', key=key)\n    handle.respond(serialize(response))\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoServer.exists","title":"exists()","text":"<pre><code>exists(\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None\n</code></pre> <p>Check if key exists within local dictionary.</p> <p>Parameters:</p> <ul> <li> <code>handle</code>             (<code>Handle</code>)         \u2013          <p>The client handle.</p> </li> <li> <code>bulk_str</code>             (<code>Bulk</code>)         \u2013          <p>The buffer that will store shared data.</p> </li> <li> <code>bulk_size</code>             (<code>int</code>)         \u2013          <p>The size of the data to be received.</p> </li> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>The data's key.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def exists(\n    self,\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None:\n    \"\"\"Check if key exists within local dictionary.\n\n    Args:\n        handle: The client handle.\n        bulk_str: The buffer that will store shared data.\n        bulk_size: The size of the data to be received.\n        key: The data's key.\n    \"\"\"\n    exists = key.obj_id in self.data\n    response = RPCResponse(operation='exists', key=key, exists=exists)\n    handle.respond(serialize(response))\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoServer.get","title":"get()","text":"<pre><code>get(\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None\n</code></pre> <p>Return data at a given key back to the client.</p> <p>Parameters:</p> <ul> <li> <code>handle</code>             (<code>Handle</code>)         \u2013          <p>The client handle.</p> </li> <li> <code>bulk_str</code>             (<code>Bulk</code>)         \u2013          <p>The buffer that will store shared data.</p> </li> <li> <code>bulk_size</code>             (<code>int</code>)         \u2013          <p>The size of the data to be received.</p> </li> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>The data's key.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def get(\n    self,\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None:\n    \"\"\"Return data at a given key back to the client.\n\n    Args:\n        handle: The client handle.\n        bulk_str: The buffer that will store shared data.\n        bulk_size: The size of the data to be received.\n        key: The data's key.\n    \"\"\"\n    local_array = self.data.get(key.obj_id, None)\n    if local_array is not None:\n        local_bulk = self.engine.create_bulk(local_array, bulk.read_only)\n        self.engine.transfer(\n            bulk.push,\n            handle.get_addr(),\n            bulk_str,\n            0,\n            local_bulk,\n            0,\n            bulk_size,\n        )\n        response = RPCResponse(operation='get', key=key, exists=True)\n    else:\n        response = RPCResponse(operation='get', key=key, exists=False)\n    handle.respond(serialize(response))\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.MargoServer.put","title":"put()","text":"<pre><code>put(\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None\n</code></pre> <p>Obtain data from the client and store it in local dictionary.</p> <p>Parameters:</p> <ul> <li> <code>handle</code>             (<code>Handle</code>)         \u2013          <p>The client handle.</p> </li> <li> <code>bulk_str</code>             (<code>Bulk</code>)         \u2013          <p>The buffer containing the data to be shared.</p> </li> <li> <code>bulk_size</code>             (<code>int</code>)         \u2013          <p>The size of the data being transferred.</p> </li> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>The data key.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def put(\n    self,\n    handle: Handle,\n    bulk_str: Bulk,\n    bulk_size: int,\n    key: DIMKey,\n) -&gt; None:\n    \"\"\"Obtain data from the client and store it in local dictionary.\n\n    Args:\n        handle: The client handle.\n        bulk_str: The buffer containing the data to be shared.\n        bulk_size: The size of the data being transferred.\n        key: The data key.\n    \"\"\"\n    local_buffer = bytearray(bulk_size)\n    local_bulk = self.engine.create_bulk(local_buffer, bulk.write_only)\n    self.engine.transfer(\n        bulk.pull,\n        handle.get_addr(),\n        bulk_str,\n        0,\n        local_bulk,\n        0,\n        bulk_size,\n    )\n    self.data[key.obj_id] = local_buffer\n\n    response = RPCResponse(operation='put', key=key)\n    handle.respond(serialize(response))\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.start_server","title":"start_server()","text":"<pre><code>start_server(url: str) -&gt; None\n</code></pre> <p>Start and wait on a Margo server.</p> <p>Parameters:</p> <ul> <li> <code>url</code>             (<code>str</code>)         \u2013          <p>URL of the engine that will be started. Should take the form <code>{protocol}://{host}:{port}</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def start_server(url: str) -&gt; None:\n    \"\"\"Start and wait on a Margo server.\n\n    Args:\n        url: URL of the engine that will be started. Should take\n            the form `{protocol}://{host}:{port}`.\n    \"\"\"\n    server_engine = Engine(url)\n    server_engine.on_finalize(_when_finalize)\n    server_engine.enable_remote_shutdown()\n\n    receiver = MargoServer(server_engine)\n    server_engine.register('evict', receiver.evict)\n    server_engine.register('exists', receiver.exists)\n    server_engine.register('get', receiver.get)\n    server_engine.register('put', receiver.put)\n    server_engine.wait_for_finalize()\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.spawn_server","title":"spawn_server()","text":"<pre><code>spawn_server(\n    protocol: str,\n    address: str,\n    port: int,\n    *,\n    spawn_timeout: float = 5.0,\n    kill_timeout: float | None = 1.0\n) -&gt; SpawnProcess\n</code></pre> <p>Spawn a local server running in a separate process.</p> Note <p>An <code>atexit</code> callback is registered which will terminate the spawned server process when the calling process exits.</p> <p>Parameters:</p> <ul> <li> <code>protocol</code>             (<code>str</code>)         \u2013          <p>Communication protocol.</p> </li> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Host IP of the server to wait on.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port of the server to wait on.</p> </li> <li> <code>spawn_timeout</code>             (<code>float</code>, default:                 <code>5.0</code> )         \u2013          <p>Max time in seconds to wait for the server to start.</p> </li> <li> <code>kill_timeout</code>             (<code>float | None</code>, default:                 <code>1.0</code> )         \u2013          <p>Max time in seconds to wait for the server to shutdown on exit.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SpawnProcess</code>         \u2013          <p>The process that the server is running in.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def spawn_server(\n    protocol: str,\n    address: str,\n    port: int,\n    *,\n    spawn_timeout: float = 5.0,\n    kill_timeout: float | None = 1.0,\n) -&gt; multiprocessing.context.SpawnProcess:\n    \"\"\"Spawn a local server running in a separate process.\n\n    Note:\n        An `atexit` callback is registered which will terminate the spawned\n        server process when the calling process exits.\n\n    Args:\n        protocol: Communication protocol.\n        address: Host IP of the server to wait on.\n        port: Port of the server to wait on.\n        spawn_timeout: Max time in seconds to wait for the server to start.\n        kill_timeout: Max time in seconds to wait for the server to shutdown\n            on exit.\n\n    Returns:\n        The process that the server is running in.\n    \"\"\"\n    url = f'{protocol}://{address}:{port}'\n\n    ctx = multiprocessing.get_context('spawn')\n    server_process = ctx.Process(\n        target=start_server,\n        args=(url,),\n    )\n    server_process.start()\n\n    def _kill_on_exit() -&gt; None:  # pragma: no cover\n        if server_process.is_alive():\n            server_process.terminate()\n            server_process.join(timeout=kill_timeout)\n            if server_process.is_alive():\n                server_process.kill()\n                server_process.join()\n            logger.debug(\n                'Server terminated on parent process exit '\n                f'(pid={server_process.pid})',\n            )\n\n    atexit.register(_kill_on_exit)\n    logger.debug('Registered server cleanup atexit callback')\n\n    wait_for_server(protocol, address, port, timeout=spawn_timeout)\n    logger.debug(\n        f'Server started (address={url}, pid={server_process.pid})',\n    )\n\n    return server_process\n</code></pre>"},{"location":"api/connectors/dim/margo/#proxystore_ex.connectors.dim.margo.wait_for_server","title":"wait_for_server()","text":"<pre><code>wait_for_server(\n    protocol: str,\n    address: str,\n    port: int,\n    timeout: float = 0.1,\n) -&gt; None\n</code></pre> <p>Wait until the server responds.</p> Warning <p>Due to how Margo blocks internally, the timeout is not very accurate.</p> <p>Parameters:</p> <ul> <li> <code>protocol</code>             (<code>str</code>)         \u2013          <p>Communication protocol.</p> </li> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Host IP of the server to wait on.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port of the server to wait on.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>0.1</code> )         \u2013          <p>The max time in seconds to wait for server response.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If the server does not respond within the timeout.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/margo.py</code> <pre><code>def wait_for_server(\n    protocol: str,\n    address: str,\n    port: int,\n    timeout: float = 0.1,\n) -&gt; None:\n    \"\"\"Wait until the server responds.\n\n    Warning:\n        Due to how Margo blocks internally, the timeout is not very accurate.\n\n    Args:\n        protocol: Communication protocol.\n        address: Host IP of the server to wait on.\n        port: Port of the server to wait on.\n        timeout: The max time in seconds to wait for server response.\n\n    Raises:\n        ServerTimeoutError: If the server does not respond within the timeout.\n    \"\"\"\n    engine = Engine(protocol, mode=pymargo.client, use_progress_thread=True)\n    remote_function = engine.register('exists')\n    key = DIMKey(\n        'margo',\n        obj_id='ping',\n        size=0,\n        peer_host=address,\n        peer_port=port,\n    )\n    rpc = RPC('exists', key=key)\n    url = f'{protocol}://{address}:{port}'\n\n    sleep_time = 0.01\n    start = time.time()\n    while time.time() - start &lt; timeout:\n        try:\n            local_url = engine.lookup(url)\n            result = remote_function.on(local_url)(\n                rpc.data,\n                rpc.key.size,\n                rpc.key,\n            )\n            response = deserialize(result)\n            assert response.exception is None\n            # We could call engine.finalize() now to be safe but Margo\n            # raises a _pymargo.MargoException: margo_addr_free() returned 11\n            # exception.\n            return\n        except MargoException:  # pragma: no cover\n            time.sleep(sleep_time)\n\n    raise ServerTimeoutError(\n        f'Failed to connect to server within timeout ({timeout} seconds).',\n    )\n</code></pre>"},{"location":"api/connectors/dim/models/","title":"proxystore_ex.connectors.dim.models","text":"<code>proxystore_ex/connectors/dim/models.py</code> <p>Message types for communication with DIM servers.</p>"},{"location":"api/connectors/dim/models/#proxystore_ex.connectors.dim.models.DIMKey","title":"DIMKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to objects stored across <code>UCXConnector</code>s.</p> <p>Attributes:</p> <ul> <li> <code>dim_type</code>             (<code>Literal['margo', 'ucx', 'zmq']</code>)         \u2013          <p>Type of DIM this key belongs to.</p> </li> <li> <code>obj_id</code>             (<code>str</code>)         \u2013          <p>Unique object key.</p> </li> <li> <code>size</code>             (<code>int</code>)         \u2013          <p>Object size in bytes.</p> </li> <li> <code>peer_host</code>             (<code>str</code>)         \u2013          <p>Hostname of peer where object is located.</p> </li> <li> <code>peer_port</code>             (<code>int</code>)         \u2013          <p>Port of peer server where object is located.</p> </li> </ul>"},{"location":"api/connectors/dim/models/#proxystore_ex.connectors.dim.models.RPC","title":"RPC  <code>dataclass</code>","text":"<pre><code>RPC(\n    operation: Literal[\"exists\", \"evict\", \"get\", \"put\"],\n    key: DIMKey,\n    data: bytes | None = None,\n)\n</code></pre> <p>Client request to a DIM server.</p> <p>Attributes:</p> <ul> <li> <code>operation</code>             (<code>Literal['exists', 'evict', 'get', 'put']</code>)         \u2013          <p>Operation type requested.</p> </li> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key to operate on.</p> </li> <li> <code>size</code>             (<code>DIMKey</code>)         \u2013          <p>Size of data associated with key.</p> </li> <li> <code>data</code>             (<code>bytes | None</code>)         \u2013          <p>Data associated with <code>set</code> operation.</p> </li> </ul>"},{"location":"api/connectors/dim/models/#proxystore_ex.connectors.dim.models.RPCResponse","title":"RPCResponse  <code>dataclass</code>","text":"<pre><code>RPCResponse(\n    operation: Literal[\"exists\", \"evict\", \"get\", \"put\"],\n    key: DIMKey,\n    data: bytes | None = None,\n    exists: bool | None = None,\n    exception: Exception | None = None,\n)\n</code></pre> <p>Server response to a client request.</p> <p>Attributes:</p> <ul> <li> <code>operation</code>             (<code>Literal['exists', 'evict', 'get', 'put']</code>)         \u2013          <p>Operation type performed.</p> </li> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key that was operated on.</p> </li> <li> <code>size</code>             (<code>DIMKey</code>)         \u2013          <p>Size of data associated with key.</p> </li> <li> <code>data</code>             (<code>bytes | None</code>)         \u2013          <p>Data returned by <code>get</code> operation.</p> </li> <li> <code>exists</code>             (<code>bool | None</code>)         \u2013          <p>Return value for <code>exists</code> operation.</p> </li> <li> <code>exception</code>             (<code>Exception | None</code>)         \u2013          <p>Optional exception raised by the operation.</p> </li> </ul>"},{"location":"api/connectors/dim/ucx/","title":"proxystore_ex.connectors.dim.ucx","text":"<code>proxystore_ex/connectors/dim/ucx.py</code> <p>UCX-based distributed in-memory connector implementation.</p>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector","title":"UCXConnector","text":"<pre><code>UCXConnector(\n    port: int,\n    address: str | None = None,\n    interface: str | None = None,\n    timeout: float = 1,\n)\n</code></pre> <p>UCX-based distributed in-memory connector.</p> Note <p>The first instance of this connector created on a process will spawn a <code>UCXServer</code> that will store data. Hence, this connector just acts as an interface to that server.</p> <p>Parameters:</p> <ul> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>The desired port for the spawned server.</p> </li> <li> <code>address</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>The IP address of the network interface to use. Has precedence over <code>interface</code> if both are provided.</p> </li> <li> <code>interface</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>The network interface to use. <code>address</code> has precedence if both args are defined.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Timeout in seconds to try connecting to local server before spawning one.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If a local server cannot be connected to within <code>timeout</code> seconds, and a new local server does not response within <code>timeout</code> seconds after being started.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def __init__(\n    self,\n    port: int,\n    address: str | None = None,\n    interface: str | None = None,\n    timeout: float = 1,\n) -&gt; None:\n    if ucx_import_error is not None:  # pragma: no cover\n        raise ucx_import_error\n\n    self._address = address\n    self._interface = interface\n    self.port = port\n    self.timeout = timeout\n\n    if self._address is not None:\n        self.address = self._address\n    elif self._interface is not None:\n        self.address = ucp.get_address(ifname=self._interface)\n    else:\n        self.address = ucp.get_address()\n\n    self.url = f'{self.address}:{self.port}'\n\n    self.server: multiprocessing.context.SpawnProcess | None\n    try:\n        logger.info(\n            f'Connecting to local server (URL={self.url})...',\n        )\n        wait_for_server(self.address, self.port, self.timeout)\n        logger.info(\n            f'Connected to local server (URL={self.url})',\n        )\n    except ServerTimeoutError:\n        logger.info(\n            'Failed to connect to local server '\n            f'(URL={self.url}, timeout={self.timeout})',\n        )\n        self.server = spawn_server(\n            self.address,\n            self.port,\n            spawn_timeout=self.timeout,\n        )\n        logger.info(f'Spawned local server (address={self.url})')\n    else:\n        self.server = None\n\n    try:\n        self._loop = asyncio.get_running_loop()\n    except RuntimeError:\n        self._loop = asyncio.new_event_loop()\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.close","title":"close()","text":"<pre><code>close(kill_server: bool = False) -&gt; None\n</code></pre> <p>Close the connector.</p> <p>Parameters:</p> <ul> <li> <code>kill_server</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to kill the server process. If this instance did not spawn the local node's server process, this is a no-op.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def close(self, kill_server: bool = False) -&gt; None:\n    \"\"\"Close the connector.\n\n    Args:\n        kill_server: Whether to kill the server process. If this instance\n            did not spawn the local node's server process, this is a\n            no-op.\n    \"\"\"\n    if kill_server and self.server is not None:\n        self.server.terminate()\n        self.server.join()\n        logger.info(\n            'Terminated local server on connector close '\n            f'(pid={self.server.pid})',\n        )\n\n    logger.debug('Closed UCX connector')\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'address': self._address,\n        'interface': self._interface,\n        'port': self.port,\n        'timeout': self.timeout,\n    }\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; UCXConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; UCXConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.evict","title":"evict()","text":"<pre><code>evict(key: DIMKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def evict(self, key: DIMKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    rpc = RPC(operation='evict', key=key)\n    self._send_rpcs([rpc])\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.exists","title":"exists()","text":"<pre><code>exists(key: DIMKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def exists(self, key: DIMKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    rpc = RPC(operation='exists', key=key)\n    (response,) = self._send_rpcs([rpc])\n    assert response.exists is not None\n    return response.exists\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.get","title":"get()","text":"<pre><code>get(key: DIMKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def get(self, key: DIMKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    rpc = RPC(operation='get', key=key)\n    (result,) = self._send_rpcs([rpc])\n    return result.data\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[DIMKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[DIMKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def get_batch(self, keys: Sequence[DIMKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    rpcs = [RPC(operation='get', key=key) for key in keys]\n    responses = self._send_rpcs(rpcs)\n    return [r.data for r in responses]\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; DIMKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DIMKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def put(self, obj: bytes) -&gt; DIMKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = DIMKey(\n        dim_type='ucx',\n        obj_id=str(uuid.uuid4()),\n        size=len(obj),\n        peer_host=self.address,\n        peer_port=self.port,\n    )\n    rpc = RPC(operation='put', key=key, data=obj)\n    self._send_rpcs([rpc])\n    return key\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[DIMKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[DIMKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[DIMKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    keys = [\n        DIMKey(\n            dim_type='ucx',\n            obj_id=str(uuid.uuid4()),\n            size=len(obj),\n            peer_host=self.address,\n            peer_port=self.port,\n        )\n        for obj in objs\n    ]\n    rpcs = [\n        RPC(operation='put', key=key, data=obj)\n        for key, obj in zip(keys, objs)\n    ]\n    self._send_rpcs(rpcs)\n    return keys\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer","title":"UCXServer","text":"<pre><code>UCXServer()\n</code></pre> <p>UCXServer implementation.</p> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.data: dict[str, bytes] = {}\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer.evict","title":"evict()","text":"<pre><code>evict(key: str) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def evict(self, key: str) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    self.data.pop(key, None)\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer.exists","title":"exists()","text":"<pre><code>exists(key: str) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def exists(self, key: str) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    return key in self.data\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer.get","title":"get()","text":"<pre><code>get(key: str) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Data or <code>None</code> if no data associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def get(self, key: str) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Data or `None` if no data associated with the key exists.\n    \"\"\"\n    return self.data.get(key, None)\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer.put","title":"put()","text":"<pre><code>put(key: str, data: bytes) -&gt; None\n</code></pre> <p>Put data in the store.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with data.</p> </li> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Data to put in the store.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def put(self, key: str, data: bytes) -&gt; None:\n    \"\"\"Put data in the store.\n\n    Args:\n        key: Key associated with data.\n        data: Data to put in the store.\n    \"\"\"\n    self.data[key] = data\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer.handle_rpc","title":"handle_rpc()","text":"<pre><code>handle_rpc(rpc: RPC) -&gt; RPCResponse\n</code></pre> <p>Process an RPC request.</p> <p>Parameters:</p> <ul> <li> <code>rpc</code>             (<code>RPC</code>)         \u2013          <p>Client RPC to process.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RPCResponse</code>         \u2013          <p>Response containing result or an exception if the operation failed.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def handle_rpc(self, rpc: RPC) -&gt; RPCResponse:\n    \"\"\"Process an RPC request.\n\n    Args:\n        rpc: Client RPC to process.\n\n    Returns:\n        Response containing result or an exception if the operation failed.\n    \"\"\"\n    response: RPCResponse\n\n    try:\n        if rpc.operation == 'exists':\n            exists = self.exists(rpc.key.obj_id)\n            response = RPCResponse('exists', key=rpc.key, exists=exists)\n        elif rpc.operation == 'evict':\n            self.evict(rpc.key.obj_id)\n            response = RPCResponse('evict', key=rpc.key)\n        elif rpc.operation == 'get':\n            data = self.get(rpc.key.obj_id)\n            response = RPCResponse('get', key=rpc.key, data=data)\n        elif rpc.operation == 'put':\n            assert rpc.data is not None\n            self.put(rpc.key.obj_id, rpc.data)\n            response = RPCResponse('put', key=rpc.key)\n        else:\n            raise AssertionError('Unreachable.')\n    except Exception as e:\n        response = RPCResponse(rpc.operation, key=rpc.key, exception=e)\n    return response\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.UCXServer.handler","title":"handler()  <code>async</code>","text":"<pre><code>handler(ep: Endpoint) -&gt; None\n</code></pre> <p>Handle endpoint requests.</p> <p>Parameters:</p> <ul> <li> <code>ep</code>             (<code>Endpoint</code>)         \u2013          <p>The endpoint making the request.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>async def handler(self, ep: ucp.Endpoint) -&gt; None:\n    \"\"\"Handle endpoint requests.\n\n    Args:\n        ep: The endpoint making the request.\n    \"\"\"\n    rpc_bytes = bytes(await ep.recv_obj())\n\n    if rpc_bytes == b'ping':\n        await ep.send_obj(b'pong')\n        return\n\n    rpc: RPC = deserialize(rpc_bytes)\n    response = self.handle_rpc(rpc)\n\n    message = serialize(response)\n    await ep.send_obj(message)\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.run_server","title":"run_server()  <code>async</code>","text":"<pre><code>run_server(port: int) -&gt; None\n</code></pre> <p>Listen and reply to RPCs from clients.</p> Warning <p>This function does not return until SIGINT or SIGTERM is received.</p> <p>Parameters:</p> <ul> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port the server should listen on.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>async def run_server(port: int) -&gt; None:  # pragma: no cover\n    \"\"\"Listen and reply to RPCs from clients.\n\n    Warning:\n        This function does not return until SIGINT or SIGTERM is received.\n\n    Args:\n        port: Port the server should listen on.\n    \"\"\"\n    server = UCXServer()\n    ucp_listener = ucp.create_listener(server.handler, port)\n\n    loop = asyncio.get_running_loop()\n    close_future = loop.create_future()\n    loop.add_signal_handler(signal.SIGINT, close_future.set_result, None)\n    loop.add_signal_handler(signal.SIGTERM, close_future.set_result, None)\n\n    await close_future\n    ucp_listener.close()\n\n    while not ucp_listener.closed():\n        await asyncio.sleep(0.001)\n\n    loop.remove_signal_handler(signal.SIGINT)\n    loop.remove_signal_handler(signal.SIGTERM)\n\n    # UCP does reference counting of open resources\n    del ucp_listener\n    await reset_ucp_async()\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.start_server","title":"start_server()","text":"<pre><code>start_server(port: int) -&gt; None\n</code></pre> <p>Run a local server.</p> Note <p>This function creates an event loop and executes <code>run_server()</code> within that loop.</p> <p>Parameters:</p> <ul> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port the server should listen on.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def start_server(port: int) -&gt; None:  # pragma: no cover\n    \"\"\"Run a local server.\n\n    Note:\n        This function creates an event loop and executes\n        [`run_server()`][proxystore_ex.connectors.dim.ucx.run_server] within\n        that loop.\n\n    Args:\n        port: Port the server should listen on.\n    \"\"\"\n    asyncio.run(run_server(port))\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.spawn_server","title":"spawn_server()","text":"<pre><code>spawn_server(\n    address: str,\n    port: int,\n    *,\n    spawn_timeout: float = 5.0,\n    kill_timeout: float | None = 1.0\n) -&gt; SpawnProcess\n</code></pre> <p>Spawn a local server running in a separate process.</p> Note <p>An <code>atexit</code> callback is registered which will terminate the spawned server process when the calling process exits.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>IP address the server will listen on.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port the server will listen on.</p> </li> <li> <code>spawn_timeout</code>             (<code>float</code>, default:                 <code>5.0</code> )         \u2013          <p>Max time in seconds to wait for the server to start.</p> </li> <li> <code>kill_timeout</code>             (<code>float | None</code>, default:                 <code>1.0</code> )         \u2013          <p>Max time in seconds to wait for the server to shutdown on exit.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SpawnProcess</code>         \u2013          <p>The process that the server is running in.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def spawn_server(\n    address: str,\n    port: int,\n    *,\n    spawn_timeout: float = 5.0,\n    kill_timeout: float | None = 1.0,\n) -&gt; multiprocessing.context.SpawnProcess:\n    \"\"\"Spawn a local server running in a separate process.\n\n    Note:\n        An `atexit` callback is registered which will terminate the spawned\n        server process when the calling process exits.\n\n    Args:\n        address: IP address the server will listen on.\n        port: Port the server will listen on.\n        spawn_timeout: Max time in seconds to wait for the server to start.\n        kill_timeout: Max time in seconds to wait for the server to shutdown\n            on exit.\n\n    Returns:\n        The process that the server is running in.\n    \"\"\"\n    ctx = multiprocessing.get_context('spawn')\n    # UCX seems to hang if you fork a process after calling ucp.init().\n    # If discovered this via a comment in Dask's distributed communication:\n    # https://github.com/dask/distributed/blob/76bbfaf9f4a14906cbf4500ed42c442c7a5bc971/distributed/comm/ucx.py#L40  # noqa: E501\n    server_process = ctx.Process(\n        target=start_server,\n        args=(port,),\n    )\n    server_process.start()\n\n    def _kill_on_exit() -&gt; None:  # pragma: no cover\n        server_process.terminate()\n        server_process.join(timeout=kill_timeout)\n        if server_process.is_alive():\n            server_process.kill()\n            server_process.join()\n        logger.debug(\n            'Server terminated on parent process exit '\n            f'(pid={server_process.pid})',\n        )\n\n    atexit.register(_kill_on_exit)\n    logger.debug('Registered server cleanup atexit callback')\n\n    wait_for_server(address, port, timeout=spawn_timeout)\n    logger.debug(\n        'Server started '\n        f'(host={address}, port={port}, pid={server_process.pid})',\n    )\n\n    return server_process\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.wait_for_server_async","title":"wait_for_server_async()  <code>async</code>","text":"<pre><code>wait_for_server_async(\n    address: str, port: int, timeout: float = 0.1\n) -&gt; None\n</code></pre> <p>Wait until the server responds.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Host IP of the server to ping.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port of the server to ping.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>0.1</code> )         \u2013          <p>Max time in seconds to wait for server response.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If the server does not respond within the timeout.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>async def wait_for_server_async(\n    address: str,\n    port: int,\n    timeout: float = 0.1,\n) -&gt; None:\n    \"\"\"Wait until the server responds.\n\n    Args:\n        address: Host IP of the server to ping.\n        port: Port of the server to ping.\n        timeout: Max time in seconds to wait for server response.\n\n    Raises:\n        ServerTimeoutError: If the server does not respond within the timeout.\n    \"\"\"\n    sleep_time = 0.01\n    time_waited = 0.0\n\n    while True:\n        try:\n            ep = await ucp.create_endpoint(address, port)\n        except ucp._libs.exceptions.UCXNotConnected as e:  # pragma: no cover\n            if time_waited &gt;= timeout:\n                raise ServerTimeoutError(\n                    'Failed to connect to server within timeout '\n                    f'({timeout} seconds).',\n                ) from e\n            await asyncio.sleep(sleep_time)\n            time_waited += sleep_time\n        else:\n            break  # pragma: no cover\n\n    await ep.send_obj(b'ping')\n    assert bytes(await ep.recv_obj()) == b'pong'\n    await ep.close()\n    assert ep.closed()\n    del ep\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.wait_for_server","title":"wait_for_server()","text":"<pre><code>wait_for_server(\n    address: str, port: int, timeout: float = 0.1\n) -&gt; None\n</code></pre> <p>Wait until the server responds.</p> Note <p>This function calls <code>wait_for_server_async()</code> using <code>asyncio.run()</code>.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>The host IP of the server to ping.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Theport of the server to ping.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>0.1</code> )         \u2013          <p>The max time in seconds to wait for server response.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If the server does not respond within the timeout.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>def wait_for_server(address: str, port: int, timeout: float = 0.1) -&gt; None:\n    \"\"\"Wait until the server responds.\n\n    Note:\n        This function calls\n        [`wait_for_server_async()`][proxystore_ex.connectors.dim.ucx.wait_for_server_async]\n        using [`asyncio.run()`][asyncio.run].\n\n    Args:\n        address: The host IP of the server to ping.\n        port: Theport of the server to ping.\n        timeout: The max time in seconds to wait for server response.\n\n    Raises:\n        ServerTimeoutError: If the server does not respond within the timeout.\n    \"\"\"\n    asyncio.run(wait_for_server_async(address, port, timeout))\n</code></pre>"},{"location":"api/connectors/dim/ucx/#proxystore_ex.connectors.dim.ucx.reset_ucp_async","title":"reset_ucp_async()  <code>async</code>","text":"<pre><code>reset_ucp_async(reset_ucp: bool = True) -&gt; None\n</code></pre> <p>Hard reset all of UCP.</p> <p>UCP provides <code>ucp.reset()</code>; however, this function does not correctly shutdown all asyncio tasks and readers. This function wraps <code>ucp.reset()</code> and additionally removes all readers on the event loop and cancels/awaits all asyncio tasks.</p> Source code in <code>proxystore_ex/connectors/dim/ucx.py</code> <pre><code>async def reset_ucp_async(reset_ucp: bool = True) -&gt; None:  # pragma: no cover\n    \"\"\"Hard reset all of UCP.\n\n    UCP provides `ucp.reset()`; however, this function does not correctly\n    shutdown all asyncio tasks and readers. This function wraps\n    `ucp.reset()` and additionally removes all readers on the event loop\n    and cancels/awaits all asyncio tasks.\n    \"\"\"\n\n    async def inner_context() -&gt; None:\n        ctx = ucp.core._get_ctx()\n\n        for task in ctx.progress_tasks:\n            if task is None:\n                continue\n            task.event_loop.remove_reader(ctx.epoll_fd)\n            if task.asyncio_task is not None:\n                try:\n                    task.asyncio_task.cancel()\n                    await task.asyncio_task\n                # A RuntimeError can happen if the task if from a different\n                # event loop. We'll just skip these for now\n                except (asyncio.CancelledError, RuntimeError):\n                    pass\n\n    # We access ucp.core._get_ctx() inside this nested function so our local\n    # reference to the UCP context goes out of scope before calling\n    # ucp.reset(). ucp.reset() will fail if there are any weak references to\n    # to the UCP context because it assumes those may be Listeners or\n    # Endpoints that were not properly closed.\n    await inner_context()\n\n    if reset_ucp:\n        try:\n            ucp.reset()\n        except ucp.UCXError:\n            pass\n</code></pre>"},{"location":"api/connectors/dim/utils/","title":"proxystore_ex.connectors.dim.utils","text":"<code>proxystore_ex/connectors/dim/utils.py</code> <p>Shared functions used by DIM stores.</p>"},{"location":"api/connectors/dim/utils/#proxystore_ex.connectors.dim.utils.get_ip_address","title":"get_ip_address()","text":"<pre><code>get_ip_address(ifname: str) -&gt; str\n</code></pre> <p>Get ip address provided an interface name.</p> Warning <p>This function does not work on MacOS/Darwin.</p> <p>Parameters:</p> <ul> <li> <code>ifname</code>             (<code>str</code>)         \u2013          <p>The interface name.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>The IP address.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/utils.py</code> <pre><code>def get_ip_address(ifname: str) -&gt; str:  # pragma: darwin no cover\n    \"\"\"Get ip address provided an interface name.\n\n    Warning:\n        This function does not work on MacOS/Darwin.\n\n    Args:\n        ifname: The interface name.\n\n    Returns:\n        The IP address.\n    \"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    return socket.inet_ntoa(\n        fcntl.ioctl(\n            s.fileno(),\n            0x8915,\n            struct.pack(\n                '256s',\n                bytes(ifname[:15], 'utf-8'),\n            ),  # SIOCGIFADDR\n        )[20:24],\n    )\n</code></pre>"},{"location":"api/connectors/dim/zmq/","title":"proxystore_ex.connectors.dim.zmq","text":"<code>proxystore_ex/connectors/dim/zmq.py</code> <p>ZeroMQ-based distributed in-memory connector implementation.</p>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector","title":"ZeroMQConnector","text":"<pre><code>ZeroMQConnector(\n    port: int,\n    address: str | None = None,\n    interface: str | None = None,\n    chunk_length: int | None = None,\n    timeout: float = 1,\n)\n</code></pre> <p>ZeroMQ-based distributed in-memory connector.</p> Note <p>The first instance of this connector created on a process will spawn a <code>ZeroMQServer</code> that will store data. Hence, this connector just acts as an interface to that server.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>The network IP address to use. Takes precedence over <code>interface</code> if both are provided.</p> </li> <li> <code>interface</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>The network interface to use. <code>address</code> arg takes precedence if both are provided.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>The desired port for the spawned server.</p> </li> <li> <code>chunk_length</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Message chunk size in bytes. Defaults to <code>MAX_CHUNK_LENGTH_DEFAULT</code>.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Timeout in seconds to try connecting to local server before spawning one.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If a local server cannot be connected to within <code>timeout</code> seconds, and a new local server does not response within <code>timeout</code> seconds after being started.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def __init__(\n    self,\n    port: int,\n    address: str | None = None,\n    interface: str | None = None,\n    chunk_length: int | None = None,\n    timeout: float = 1,\n) -&gt; None:\n    # ZMQ is not a default dependency so we don't want to raise\n    # an error unless the user actually tries to use this code\n    if zmq_import_error is not None:  # pragma: no cover\n        raise zmq_import_error\n\n    self._address = address\n    self._interface = interface\n    self.port = port\n    self.chunk_length = (\n        MAX_CHUNK_LENGTH_DEFAULT if chunk_length is None else chunk_length\n    )\n    self.timeout = timeout\n\n    if self._address is not None:\n        self.address = self._address\n    elif self._interface is not None:  # pragma: darwin no cover\n        self.address = get_ip_address(self._interface)\n    else:\n        host = socket.gethostname()\n        self.address = socket.gethostbyname(host)\n\n    self.url = f'tcp://{self.address}:{self.port}'\n\n    self.server: multiprocessing.Process | None\n    try:\n        logger.info(\n            f'Connecting to local server (url={self.url})...',\n        )\n        wait_for_server(self.address, self.port, self.timeout)\n        logger.info(\n            f'Connected to local server (url={self.url})',\n        )\n    except ServerTimeoutError:\n        logger.info(\n            'Failed to connect to local server '\n            f'(address={self.url}, timeout={self.timeout})',\n        )\n        self.server = spawn_server(\n            self.address,\n            self.port,\n            chunk_length=self.chunk_length,\n            spawn_timeout=self.timeout,\n        )\n        logger.info(f'Spawned local server (url={self.url})')\n    else:\n        self.server = None\n\n    self.context = zmq.Context()\n    self.socket = self.context.socket(zmq.REQ)\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.close","title":"close()","text":"<pre><code>close(kill_server: bool = True) -&gt; None\n</code></pre> <p>Close the connector.</p> <p>Parameters:</p> <ul> <li> <code>kill_server</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to kill the server process. If this instance did not spawn the local node's server process, this is a no-op.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def close(self, kill_server: bool = True) -&gt; None:\n    \"\"\"Close the connector.\n\n    Args:\n        kill_server: Whether to kill the server process. If this instance\n            did not spawn the local node's server process, this is a\n            no-op.\n    \"\"\"\n    if kill_server and self.server is not None:\n        self.server.terminate()\n        self.server.join()\n        logger.info(\n            'Terminated local server on connector close '\n            f'(pid={self.server.pid})',\n        )\n\n    self.socket.close()\n    self.context.term()\n    logger.info('Closed ZMQ connector')\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'address': self._address,\n        'interface': self._interface,\n        'port': self.port,\n        'chunk_length': self.chunk_length,\n        'timeout': self.timeout,\n    }\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; ZeroMQConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; ZeroMQConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.evict","title":"evict()","text":"<pre><code>evict(key: DIMKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def evict(self, key: DIMKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    rpc = RPC(operation='evict', key=key)\n    self._send_rpcs([rpc])\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.exists","title":"exists()","text":"<pre><code>exists(key: DIMKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def exists(self, key: DIMKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    rpc = RPC(operation='exists', key=key)\n    (response,) = self._send_rpcs([rpc])\n    assert response.exists is not None\n    return response.exists\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.get","title":"get()","text":"<pre><code>get(key: DIMKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>DIMKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def get(self, key: DIMKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    rpc = RPC(operation='get', key=key)\n    (result,) = self._send_rpcs([rpc])\n    return result.data\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[DIMKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[DIMKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def get_batch(self, keys: Sequence[DIMKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    rpcs = [RPC(operation='get', key=key) for key in keys]\n    responses = self._send_rpcs(rpcs)\n    return [r.data for r in responses]\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; DIMKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DIMKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def put(self, obj: bytes) -&gt; DIMKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = DIMKey(\n        dim_type='zmq',\n        obj_id=str(uuid.uuid4()),\n        size=len(obj),\n        peer_host=self.address,\n        peer_port=self.port,\n    )\n    rpc = RPC(operation='put', key=key, data=obj)\n    self._send_rpcs([rpc])\n    return key\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[DIMKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[DIMKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[DIMKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    keys = [\n        DIMKey(\n            dim_type='zmq',\n            obj_id=str(uuid.uuid4()),\n            size=len(obj),\n            peer_host=self.address,\n            peer_port=self.port,\n        )\n        for obj in objs\n    ]\n    rpcs = [\n        RPC(operation='put', key=key, data=obj)\n        for key, obj in zip(keys, objs)\n    ]\n    self._send_rpcs(rpcs)\n    return keys\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQServer","title":"ZeroMQServer","text":"<pre><code>ZeroMQServer()\n</code></pre> <p>ZeroMQServer implementation.</p> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.data: dict[str, bytes] = {}\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQServer.evict","title":"evict()","text":"<pre><code>evict(key: str) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def evict(self, key: str) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    self.data.pop(key, None)\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQServer.exists","title":"exists()","text":"<pre><code>exists(key: str) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def exists(self, key: str) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    return key in self.data\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQServer.get","title":"get()","text":"<pre><code>get(key: str) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Data or <code>None</code> if no data associated with the key exists.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def get(self, key: str) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Data or `None` if no data associated with the key exists.\n    \"\"\"\n    return self.data.get(key, None)\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQServer.put","title":"put()","text":"<pre><code>put(key: str, data: bytes) -&gt; None\n</code></pre> <p>Put data in the store.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with data.</p> </li> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Data to put in the store.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def put(self, key: str, data: bytes) -&gt; None:\n    \"\"\"Put data in the store.\n\n    Args:\n        key: Key associated with data.\n        data: Data to put in the store.\n    \"\"\"\n    self.data[key] = data\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.ZeroMQServer.handle_rpc","title":"handle_rpc()","text":"<pre><code>handle_rpc(rpc: RPC) -&gt; RPCResponse\n</code></pre> <p>Process an RPC request.</p> <p>Parameters:</p> <ul> <li> <code>rpc</code>             (<code>RPC</code>)         \u2013          <p>Client RPC to process.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RPCResponse</code>         \u2013          <p>Response containing result or an exception if the operation failed.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def handle_rpc(self, rpc: RPC) -&gt; RPCResponse:\n    \"\"\"Process an RPC request.\n\n    Args:\n        rpc: Client RPC to process.\n\n    Returns:\n        Response containing result or an exception if the operation failed.\n    \"\"\"\n    response: RPCResponse\n    try:\n        if rpc.operation == 'exists':\n            exists = self.exists(rpc.key.obj_id)\n            response = RPCResponse('exists', key=rpc.key, exists=exists)\n        elif rpc.operation == 'evict':\n            self.evict(rpc.key.obj_id)\n            response = RPCResponse('evict', key=rpc.key)\n        elif rpc.operation == 'get':\n            data = self.get(rpc.key.obj_id)\n            response = RPCResponse('get', key=rpc.key, data=data)\n        elif rpc.operation == 'put':\n            assert rpc.data is not None\n            self.put(rpc.key.obj_id, rpc.data)\n            response = RPCResponse('put', key=rpc.key)\n        else:\n            raise AssertionError('Unreachable.')\n    except Exception as e:\n        response = RPCResponse(rpc.operation, key=rpc.key, exception=e)\n    return response\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.run_server","title":"run_server()  <code>async</code>","text":"<pre><code>run_server(\n    address: str, port: int, chunk_length: int | None = None\n) -&gt; None\n</code></pre> <p>Listen and reply to RPCs from clients.</p> Warning <p>This function does not return until SIGINT or SIGTERM is received.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>IP address the server should bind to.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port the server should listen on.</p> </li> <li> <code>chunk_length</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Message chunk size in bytes. Defaults to <code>MAX_CHUNK_LENGTH_DEFAULT</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>async def run_server(\n    address: str,\n    port: int,\n    chunk_length: int | None = None,\n) -&gt; None:\n    \"\"\"Listen and reply to RPCs from clients.\n\n    Warning:\n        This function does not return until SIGINT or SIGTERM is received.\n\n    Args:\n        address: IP address the server should bind to.\n        port: Port the server should listen on.\n        chunk_length: Message chunk size in bytes. Defaults to\n            `MAX_CHUNK_LENGTH_DEFAULT`.\n    \"\"\"\n    loop = asyncio.get_running_loop()\n    close_future = loop.create_future()\n\n    loop.add_signal_handler(signal.SIGINT, close_future.set_result, None)\n    loop.add_signal_handler(signal.SIGTERM, close_future.set_result, None)\n\n    server = ZeroMQServer()\n    chunk_length = (\n        MAX_CHUNK_LENGTH_DEFAULT if chunk_length is None else chunk_length\n    )\n\n    context = zmq.asyncio.Context()\n    socket = context.socket(zmq.REP)\n    socket.setsockopt(zmq.RCVTIMEO, 100)\n\n    with socket.bind(f'tcp://{address}:{port}'):\n        while not close_future.done():\n            try:\n                rpc_parts = await socket.recv_multipart()\n            except zmq.error.Again:\n                continue\n\n            rpc_bytes = b''.join(rpc_parts)\n\n            if rpc_bytes == b'ping':\n                await socket.send(b'pong')\n                continue\n\n            rpc: RPC = deserialize(rpc_bytes)\n            response = server.handle_rpc(rpc)\n\n            message = serialize(response)\n            await socket.send_multipart(\n                list(chunk_bytes(message, chunk_length)),\n            )\n\n    loop.remove_signal_handler(signal.SIGINT)\n    loop.remove_signal_handler(signal.SIGTERM)\n\n    socket.close()\n    context.term()\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.start_server","title":"start_server()","text":"<pre><code>start_server(\n    address: str, port: int, chunk_length: int | None = None\n) -&gt; None\n</code></pre> <p>Run a local server.</p> Note <p>This function creates an event loop and executes <code>run_server()</code> within that loop.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>IP address the server should bind to.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port the server should listen on.</p> </li> <li> <code>chunk_length</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Message chunk size in bytes. Defaults to <code>MAX_CHUNK_LENGTH_DEFAULT</code>.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def start_server(\n    address: str,\n    port: int,\n    chunk_length: int | None = None,\n) -&gt; None:\n    \"\"\"Run a local server.\n\n    Note:\n        This function creates an event loop and executes\n        [`run_server()`][proxystore_ex.connectors.dim.zmq.run_server] within\n        that loop.\n\n    Args:\n        address: IP address the server should bind to.\n        port: Port the server should listen on.\n        chunk_length: Message chunk size in bytes. Defaults to\n            `MAX_CHUNK_LENGTH_DEFAULT`.\n    \"\"\"\n    asyncio.run(run_server(address, port, chunk_length))\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.spawn_server","title":"spawn_server()","text":"<pre><code>spawn_server(\n    address: str,\n    port: int,\n    *,\n    chunk_length: int | None = None,\n    spawn_timeout: float = 5.0,\n    kill_timeout: float | None = 1.0\n) -&gt; Process\n</code></pre> <p>Spawn a local server running in a separate process.</p> Note <p>An <code>atexit</code> callback is registered which will terminate the spawned server process when the calling process exits.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>IP address the server should bind to.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port the server will listen on.</p> </li> <li> <code>chunk_length</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Message chunk size in bytes. Defaults to <code>MAX_CHUNK_LENGTH_DEFAULT</code>.</p> </li> <li> <code>spawn_timeout</code>             (<code>float</code>, default:                 <code>5.0</code> )         \u2013          <p>Max time in seconds to wait for the server to start.</p> </li> <li> <code>kill_timeout</code>             (<code>float | None</code>, default:                 <code>1.0</code> )         \u2013          <p>Max time in seconds to wait for the server to shutdown on exit.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Process</code>         \u2013          <p>The process that the server is running in.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def spawn_server(\n    address: str,\n    port: int,\n    *,\n    chunk_length: int | None = None,\n    spawn_timeout: float = 5.0,\n    kill_timeout: float | None = 1.0,\n) -&gt; multiprocessing.Process:\n    \"\"\"Spawn a local server running in a separate process.\n\n    Note:\n        An `atexit` callback is registered which will terminate the spawned\n        server process when the calling process exits.\n\n    Args:\n        address: IP address the server should bind to.\n        port: Port the server will listen on.\n        chunk_length: Message chunk size in bytes. Defaults to\n            `MAX_CHUNK_LENGTH_DEFAULT`.\n        spawn_timeout: Max time in seconds to wait for the server to start.\n        kill_timeout: Max time in seconds to wait for the server to shutdown\n            on exit.\n\n    Returns:\n        The process that the server is running in.\n    \"\"\"\n    server_process = multiprocessing.Process(\n        target=start_server,\n        args=(address, port, chunk_length),\n    )\n    server_process.start()\n\n    def _kill_on_exit() -&gt; None:  # pragma: no cover\n        server_process.terminate()\n        server_process.join(timeout=kill_timeout)\n        if server_process.is_alive():\n            server_process.kill()\n            server_process.join()\n        logger.debug(\n            'Server terminated on parent process exit '\n            f'(pid={server_process.pid})',\n        )\n\n    atexit.register(_kill_on_exit)\n    logger.debug('Registered server cleanup atexit callback')\n\n    wait_for_server(address, port, timeout=spawn_timeout)\n    logger.debug(\n        'Server started '\n        f'(host={address}, port={port}, pid={server_process.pid})',\n    )\n\n    return server_process\n</code></pre>"},{"location":"api/connectors/dim/zmq/#proxystore_ex.connectors.dim.zmq.wait_for_server","title":"wait_for_server()","text":"<pre><code>wait_for_server(\n    address: str, port: int, timeout: float = 0.1\n) -&gt; None\n</code></pre> <p>Wait until the server responds.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Host of the server to ping.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port of the server to ping.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>0.1</code> )         \u2013          <p>Max time in seconds to wait for server response.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ServerTimeoutError</code>           \u2013          <p>If the server does not respond within the timeout.</p> </li> </ul> Source code in <code>proxystore_ex/connectors/dim/zmq.py</code> <pre><code>def wait_for_server(address: str, port: int, timeout: float = 0.1) -&gt; None:\n    \"\"\"Wait until the server responds.\n\n    Args:\n        address: Host of the server to ping.\n        port: Port of the server to ping.\n        timeout: Max time in seconds to wait for server response.\n\n    Raises:\n        ServerTimeoutError: If the server does not respond within the timeout.\n    \"\"\"\n    start = time.time()\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.setsockopt(zmq.LINGER, 0)\n    socket.connect(f'tcp://{address}:{port}')\n    socket.send(b'ping')\n\n    poller = zmq.Poller()\n    poller.register(socket, zmq.POLLIN)\n\n    while time.time() - start &lt; timeout:\n        # Poll for 100ms\n        event = poller.poll(100)\n        if len(event) != 0:\n            response = socket.recv()\n            assert response == b'pong'\n            socket.close()\n            return\n\n    socket.close()\n\n    raise ServerTimeoutError(\n        f'Failed to connect to server within timeout ({timeout} seconds).',\n    )\n</code></pre>"},{"location":"api/plugins/","title":"proxystore_ex.plugins","text":"<code>proxystore_ex/plugins/__init__.py</code> <p>Plugins for third-party packages.</p>"},{"location":"api/plugins/distributed/","title":"proxystore_ex.plugins.distributed","text":"<code>proxystore_ex/plugins/distributed.py</code> <p>Custom ProxyStore client for Dask Distributed.</p>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.Client","title":"Client","text":"<pre><code>Client(\n    *args: Any,\n    ps_store: Store[Any] | None = None,\n    ps_threshold: int = 100000,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>Client</code></p> <p>Dask Distributed Client with ProxyStore support.</p> <p>This is a wrapper around <code>dask.distributed.Client</code> that proxies function arguments and return values using a provided <code>Store</code> and threshold size.</p> <p>Warning</p> <p>The custom Dask <code>Client</code> is an experimental feature and the API may change in the future. If you encounter unexpected behavior, please open a bug report.</p> <p>Using this custom client is as easy as changing your import and passing two extra arguments to the constructor.</p> example.py<pre><code>import tempfile\n\nfrom proxystore.ex.plugins.distributed import Client  # (1)!\nfrom proxystore.connectors.file import FileConnector\nfrom proxystore.store import Store\n\nwith tempfile.TemporaryDirectory() as tmp_dir:\n    with Store('default', FileConnector(tmp_dir), register=True) as store:\n        client = Client(..., ps_store=store, ps_threshold=100)  # (2)!\n\n        x = list(range(100))\n        p = store.proxy(x)\n        y = client.submit(sum, p)\n\n        print(f'Result: {y.result()}')\n\n        client.close()\n</code></pre> <ol> <li>Change the import of <code>Client</code> from <code>dask.distributed</code> to    <code>proxystore.ex.plugins.distributed</code>.</li> <li>Pass your <code>Store</code> and threshold object    size. Serialized objects larger than the threshold size in bytes will    be serialized using the store you provide and pass-by-proxy.</li> </ol> <p>The custom <code>Client</code> behaves exactly as a normal Dask client when <code>ps_store</code> is <code>None</code>. But when ProxyStore is configured, function args, kwargs, and results from passed to or from <code>Client.submit()</code> and <code>Client.map()</code> will be scanned and proxied as necessary based on their size.</p> <p>When invoking a function, you can alter this behavior by passing <code>proxy_args=False</code> and/or <code>proxy_result=False</code> to disable proxying for that specific function submission to the scheduler.</p> <p>Warning</p> <p>There are some edge cases to be aware of when using the automatic proxying. Please read the documentation for <code>Client.submit()</code> and <code>Client.map()</code> for the most up to date details.</p> <p>Parameters:</p> <ul> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments to pass to <code>dask.distributed.Client</code>.</p> </li> <li> <code>ps_store</code>             (<code>Store[Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Store to use when proxying objects.</p> </li> <li> <code>ps_threshold</code>             (<code>int</code>, default:                 <code>100000</code> )         \u2013          <p>Object size threshold in bytes. Objects larger than this threshold will be proxied.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments to pass to <code>dask.distributed.Client</code>.</p> </li> </ul> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def __init__(\n    self,\n    *args: Any,\n    ps_store: Store[Any] | None = None,\n    ps_threshold: int = 100_000,\n    **kwargs: Any,\n) -&gt; None:\n    super().__init__(*args, **kwargs)\n\n    if ps_store is not None and get_store(ps_store.name) is None:\n        warnings.warn(\n            f'The store instance named \"{ps_store.name}\" has not been '\n            'registered. This may result in two copies of the store '\n            'being initialized on this process. Call register_store() '\n            'before instantiating the Client.',\n            stacklevel=2,\n        )\n\n    self._ps_store = ps_store\n    self._ps_threshold = ps_threshold\n</code></pre>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.Client.map","title":"map()","text":"<pre><code>map(\n    func,\n    *iterables,\n    key=None,\n    workers=None,\n    retries=None,\n    resources=None,\n    priority=0,\n    allow_other_workers=False,\n    fifo_timeout=\"100 ms\",\n    actor=False,\n    actors=False,\n    pure=True,\n    batch_size=None,\n    proxy_args: bool = True,\n    proxy_result: bool = True,\n    **kwargs\n)\n</code></pre> <p>Map a function on a sequence of arguments.</p> <p>This has the same behavior as <code>Client.map()</code> but arguments and return values larger than the ProxyStore threshold size will be passed-by-proxy.</p> <p>This method adds the <code>proxy_args</code> and <code>proxy_result</code> flags (default <code>True</code>) which can be used to disable proxying of function arguments or return values, respectively, for a single invocation.</p> Note <p>Proxied arguments will be evicted from the store when the future containing the result of the function application is set. However, proxied keyword arguments shared across all functions will not be evict if they were proxied.</p> Warning <p>Unless the function is explicitly marked as not pure, a function result that gets proxied will not be automatically evicted. This is because Dask caches results of pure functions to avoid duplicate computation so it is not guaranteed to be safe to evict the function result once consumed by the client code.</p> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def map(  # type: ignore[no-untyped-def]\n    self,\n    func,\n    *iterables,\n    key=None,\n    workers=None,\n    retries=None,\n    resources=None,\n    priority=0,\n    allow_other_workers=False,\n    fifo_timeout='100 ms',\n    actor=False,\n    actors=False,\n    pure=True,\n    batch_size=None,\n    proxy_args: bool = True,\n    proxy_result: bool = True,\n    **kwargs,\n):\n    \"\"\"Map a function on a sequence of arguments.\n\n    This has the same behavior as [`Client.map()`][distributed.Client.map]\n    but arguments and return values larger than the ProxyStore threshold\n    size will be passed-by-proxy.\n\n    This method adds the `proxy_args` and `proxy_result` flags (default\n    `True`) which can be used to disable proxying of function arguments\n    or return values, respectively, for a single invocation.\n\n    Note:\n        Proxied arguments will be evicted from the store when the\n        future containing the result of the function application is set.\n        However, proxied keyword arguments shared across all functions\n        will not be evict if they were proxied.\n\n    Warning:\n        Unless the function is explicitly marked as not pure, a function\n        result that gets proxied will not be automatically evicted. This\n        is because Dask caches results of pure functions to avoid\n        duplicate computation so it is not guaranteed to be safe to evict\n        the function result once consumed by the client code.\n    \"\"\"\n    total_length = sum(len(x) for x in iterables)\n    if (\n        not (batch_size and batch_size &gt; 1 and total_length &gt; batch_size)\n        and self._ps_store is not None\n    ):\n        # map() partitions the iterators if batching needs to be performed\n        # and calls itself again on each of the batches in the iterators.\n        # In this case, we don't want to proxy the pre-batched iterators\n        # and instead want to wait to proxy until the later calls to map()\n        # on each batch.\n        key = key or funcname(func)\n        iterables = list(zip(*zip(*iterables)))  # type: ignore[assignment]\n        if not isinstance(key, list) and pure:  # pragma: no branch\n            key = [\n                f'{key}-{tokenize(func, kwargs, *args)}-proxy'\n                for args in zip(*iterables)\n            ]\n\n        iterables = tuple(\n            proxy_iterable(\n                iterable,\n                store=self._ps_store,\n                threshold=self._ps_threshold if proxy_args else None,\n                evict=False,\n            )\n            for iterable in iterables\n        )\n\n        kwargs = proxy_mapping(\n            kwargs,\n            store=self._ps_store,\n            threshold=self._ps_threshold if proxy_args else None,\n            evict=False,\n        )\n\n        func = proxy_task_wrapper(\n            func,\n            store=self._ps_store,\n            threshold=self._ps_threshold if proxy_result else None,\n            # Pure function results can be cached so we don't want to\n            # evict those once the result is consumed\n            evict=not pure,\n        )\n\n    futures = super().map(\n        func,\n        *iterables,\n        key=key,\n        workers=workers,\n        retries=retries,\n        resources=resources,\n        priority=priority,\n        allow_other_workers=allow_other_workers,\n        fifo_timeout=fifo_timeout,\n        actor=actor,\n        actors=actors,\n        pure=pure,\n        batch_size=batch_size,\n        **kwargs,\n    )\n\n    if (\n        not (batch_size and batch_size &gt; 1 and total_length &gt; batch_size)\n        and self._ps_store is not None\n    ):\n        for future, *args in zip(futures, *iterables):\n            proxied_args_keys = [\n                get_key(x) for x in args if isinstance(x, Proxy)\n            ]\n            # TODO: how to delete kwargs?\n            callback = partial(\n                _evict_proxies_callback,\n                keys=proxied_args_keys,\n                store=self._ps_store,\n            )\n            future.add_done_callback(callback)\n\n        if any(isinstance(x, Proxy) for x in kwargs.values()):\n            warnings.warn(\n                'A keyword argument to map() was proxied, but proxied '\n                'keyword arguments will not be automatically evicted. '\n                'This can lead to memory leaks.',\n                stacklevel=2,\n            )\n\n    return futures\n</code></pre>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.Client.submit","title":"submit()","text":"<pre><code>submit(\n    func,\n    *args,\n    key=None,\n    workers=None,\n    resources=None,\n    retries=None,\n    priority=0,\n    fifo_timeout=\"100 ms\",\n    allow_other_workers=False,\n    actor=False,\n    actors=False,\n    pure=True,\n    proxy_args: bool = True,\n    proxy_result: bool = True,\n    **kwargs\n)\n</code></pre> <p>Submit a function application to the scheduler.</p> <p>This has the same behavior as <code>Client.submit()</code> but arguments and return values larger than the ProxyStore threshold size will be passed-by-proxy.</p> <p>This method adds the <code>proxy_args</code> and <code>proxy_result</code> flags (default <code>True</code>) which can be used to disable proxying of function arguments or return values, respectively, for a single invocation.</p> Note <p>Proxied arguments will be evicted from the store when the future containing the result of the function application is set.</p> Warning <p>Unless the function is explicitly marked as not pure, a function result that gets proxied will not be automatically evicted. This is because Dask caches results of pure functions to avoid duplicate computation so it is not guaranteed to be safe to evict the function result once consumed by the client code.</p> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def submit(  # type: ignore[no-untyped-def]\n    self,\n    func,\n    *args,\n    key=None,\n    workers=None,\n    resources=None,\n    retries=None,\n    priority=0,\n    fifo_timeout='100 ms',\n    allow_other_workers=False,\n    actor=False,\n    actors=False,\n    pure=True,\n    proxy_args: bool = True,\n    proxy_result: bool = True,\n    **kwargs,\n):\n    \"\"\"Submit a function application to the scheduler.\n\n    This has the same behavior as\n    [`Client.submit()`][distributed.Client.submit] but arguments and\n    return values larger than the ProxyStore threshold size will be\n    passed-by-proxy.\n\n    This method adds the `proxy_args` and `proxy_result` flags (default\n    `True`) which can be used to disable proxying of function arguments\n    or return values, respectively, for a single invocation.\n\n    Note:\n        Proxied arguments will be evicted from the store when the\n        future containing the result of the function application is set.\n\n    Warning:\n        Unless the function is explicitly marked as not pure, a function\n        result that gets proxied will not be automatically evicted. This\n        is because Dask caches results of pure functions to avoid\n        duplicate computation so it is not guaranteed to be safe to evict\n        the function result once consumed by the client code.\n    \"\"\"\n    proxied_args_keys: list[ConnectorKeyT] = []\n    if self._ps_store is not None:\n        if key is None and pure:  # pragma: no branch\n            key = f'{funcname(func)}-{tokenize(func, kwargs, *args)}-proxy'\n            pure = False\n\n        args = proxy_iterable(\n            args,\n            store=self._ps_store,\n            threshold=self._ps_threshold if proxy_args else None,\n            # Don't evict data after proxy resolve because we will\n            # manually evict after the task future completes.\n            evict=False,\n        )\n        proxied_args_keys.extend(\n            get_key(x) for x in args if isinstance(x, Proxy)\n        )\n\n        kwargs = proxy_mapping(\n            kwargs,\n            store=self._ps_store,\n            threshold=self._ps_threshold if proxy_args else None,\n            evict=False,\n        )\n        proxied_args_keys.extend(\n            get_key(x) for x in kwargs.values() if isinstance(x, Proxy)\n        )\n\n        func = proxy_task_wrapper(\n            func,\n            store=self._ps_store,\n            threshold=self._ps_threshold if proxy_result else None,\n            # Pure function results can be cached so we don't want to\n            # evict those once the result is consumed\n            evict=not pure,\n        )\n\n    future = super().submit(\n        func,\n        *args,\n        key=key,\n        workers=workers,\n        resources=resources,\n        retries=retries,\n        priority=priority,\n        fifo_timeout=fifo_timeout,\n        allow_other_workers=allow_other_workers,\n        actor=actor,\n        actors=actors,\n        pure=pure,\n        **kwargs,\n    )\n\n    if self._ps_store is not None:\n        callback = partial(\n            _evict_proxies_callback,\n            keys=proxied_args_keys,\n            store=self._ps_store,\n        )\n        future.add_done_callback(callback)\n\n    return future\n</code></pre>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.proxy_by_size","title":"proxy_by_size()","text":"<pre><code>proxy_by_size(\n    x: T,\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; T | Proxy[T]\n</code></pre> <p>Serialize an object and proxy it if the object is larger enough.</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>T</code>)         \u2013          <p>Object to possibly proxy.</p> </li> <li> <code>store</code>             (<code>Store[ConnectorT]</code>)         \u2013          <p>Store to use to proxy objects.</p> </li> <li> <code>threshold</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Threshold size in bytes. If <code>None</code>, the object will not be proxied.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Evict flag value to pass to created proxies.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T | Proxy[T]</code>         \u2013          <p>The input object <code>x</code> if <code>x</code> is smaller than <code>threshold</code> otherwise         a <code>Proxy</code> of <code>x</code>.</p> </li> </ul> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def proxy_by_size(\n    x: T,\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; T | Proxy[T]:\n    \"\"\"Serialize an object and proxy it if the object is larger enough.\n\n    Args:\n        x: Object to possibly proxy.\n        store: Store to use to proxy objects.\n        threshold: Threshold size in bytes. If `None`, the object will not\n            be proxied.\n        evict: Evict flag value to pass to created proxies.\n\n    Returns:\n        The input object `x` if `x` is smaller than `threshold` otherwise \\\n        a [`Proxy`][proxystore.proxy.Proxy] of `x`.\n    \"\"\"\n    if threshold is None or isinstance(x, Proxy):\n        return x\n\n    s = serialize(x)\n\n    if len(s) &gt;= threshold:\n        proxy = store.proxy(\n            s,\n            evict=evict,\n            # We can't use populate_target here because we are passing\n            # the serialized object to store.proxy(), not the actual object.\n            # populate_target=True,\n            serializer=lambda x: x,\n            skip_nonproxiable=True,\n        )\n\n        # This is dangerous code, but is taken from the Proxy constructor\n        # to essentially mimic what populate_target=True would have done\n        # above but using the actual target object x and not the serialized s.\n        object.__setattr__(proxy, '__proxy_target__', x)\n        object.__setattr__(proxy, '__proxy_default_class__', x.__class__)\n        default_hash: Exception | int\n        try:\n            default_hash = hash(x)\n        except TypeError as e:\n            default_hash = e\n        object.__setattr__(proxy, '__proxy_default_hash__', default_hash)\n\n        return cast(Proxy[T], proxy)\n    else:\n        # In this case, we paid the cost of serializing x but did not use\n        # that serialization of x so it will be serialized again using\n        # Dask's mechanisms. This adds some overhead, but the hope is that\n        # the threshold is reasonably set such that it is only small objects\n        # which get serialized twice. Large objects above the threshold only\n        # get serialized once by ProxyStore and the lightweight proxy is\n        # serialized by Dask.\n        return x\n</code></pre>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.proxy_iterable","title":"proxy_iterable()","text":"<pre><code>proxy_iterable(\n    iterable: Iterable[Any],\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; tuple\n</code></pre> <p>Proxy values in an iterable larger than the threshold size.</p> <p>Parameters:</p> <ul> <li> <code>iterable</code>             (<code>Iterable[Any]</code>)         \u2013          <p>Iterable containing possibly large values to proxy.</p> </li> <li> <code>store</code>             (<code>Store[ConnectorT]</code>)         \u2013          <p>Store to use to proxy objects.</p> </li> <li> <code>threshold</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Threshold size in bytes. If <code>None</code>, no objects will b proxied.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Evict flag value to pass to created proxies.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>         \u2013          <p>Tuple containing the objects yielded by the iterable with objects         larger than the threshold size replaced with proxies.</p> </li> </ul> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def proxy_iterable(\n    iterable: Iterable[Any],\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; tuple:  # type: ignore[type-arg]\n    \"\"\"Proxy values in an iterable larger than the threshold size.\n\n    Args:\n        iterable: Iterable containing possibly large values to proxy.\n        store: Store to use to proxy objects.\n        threshold: Threshold size in bytes. If `None`, no objects will b\n            proxied.\n        evict: Evict flag value to pass to created proxies.\n\n    Returns:\n        Tuple containing the objects yielded by the iterable with objects \\\n        larger than the threshold size replaced with proxies.\n    \"\"\"\n    return tuple(\n        proxy_by_size(\n            value,\n            store=store,\n            threshold=threshold,\n            evict=evict,\n        )\n        for value in iterable\n    )\n</code></pre>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.proxy_mapping","title":"proxy_mapping()","text":"<pre><code>proxy_mapping(\n    mapping: Mapping[T, Any],\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; dict[T, Any]\n</code></pre> <p>Proxy values in a mapping larger than the threshold size.</p> <p>Parameters:</p> <ul> <li> <code>mapping</code>             (<code>Mapping[T, Any]</code>)         \u2013          <p>Mapping containing possibly large values to proxy.</p> </li> <li> <code>store</code>             (<code>Store[ConnectorT]</code>)         \u2013          <p>Store to use to proxy objects.</p> </li> <li> <code>threshold</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Threshold size in bytes. If <code>None</code>, no objects will b proxied.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Evict flag value to pass to created proxies.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[T, Any]</code>         \u2013          <p>Mapping containing the same keys and values as the input mapping         but objects larger than the threshold size are replaced with proxies.</p> </li> </ul> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def proxy_mapping(\n    mapping: Mapping[T, Any],\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; dict[T, Any]:\n    \"\"\"Proxy values in a mapping larger than the threshold size.\n\n    Args:\n        mapping: Mapping containing possibly large values to proxy.\n        store: Store to use to proxy objects.\n        threshold: Threshold size in bytes. If `None`, no objects will b\n            proxied.\n        evict: Evict flag value to pass to created proxies.\n\n    Returns:\n        Mapping containing the same keys and values as the input mapping \\\n        but objects larger than the threshold size are replaced with proxies.\n    \"\"\"\n    return {\n        key: proxy_by_size(\n            mapping[key],\n            store=store,\n            threshold=threshold,\n            evict=evict,\n        )\n        for key in mapping\n    }\n</code></pre>"},{"location":"api/plugins/distributed/#proxystore_ex.plugins.distributed.proxy_task_wrapper","title":"proxy_task_wrapper()","text":"<pre><code>proxy_task_wrapper(\n    func: Callable[P, T],\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; Callable[P, T | Proxy[T]]\n</code></pre> <p>Proxy task wrapper.</p> <p>Wraps a task function to proxy returns values larger than a threshold.</p> <p>Parameters:</p> <ul> <li> <code>func</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Function to wrap.</p> </li> <li> <code>store</code>             (<code>Store[ConnectorT]</code>)         \u2013          <p>Store to use to proxy the result.</p> </li> <li> <code>threshold</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Threshold size in bytes.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Evict flag value to pass to the created proxy.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Callable[P, T | Proxy[T]]</code>         \u2013          <p>Callable with the same shape as <code>func</code> but that returns either the         original return type or a factory of the return type which can be         used to construct a proxy.</p> </li> </ul> Source code in <code>proxystore_ex/plugins/distributed.py</code> <pre><code>def proxy_task_wrapper(\n    func: Callable[P, T],\n    store: Store[ConnectorT],\n    threshold: int | None = None,\n    evict: bool = True,\n) -&gt; Callable[P, T | Proxy[T]]:\n    \"\"\"Proxy task wrapper.\n\n    Wraps a task function to proxy returns values larger than a threshold.\n\n    Args:\n        func: Function to wrap.\n        store: Store to use to proxy the result.\n        threshold: Threshold size in bytes.\n        evict: Evict flag value to pass to the created proxy.\n\n    Returns:\n        Callable with the same shape as `func` but that returns either the \\\n        original return type or a factory of the return type which can be \\\n        used to construct a proxy.\n    \"\"\"\n\n    @functools.wraps(func)\n    def _proxy_wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; T | Proxy[T]:\n        result = func(*args, **kwargs)\n        proxy_or_result = proxy_by_size(\n            result,\n            store=store,\n            threshold=threshold,\n            evict=evict,\n        )\n        return proxy_or_result\n\n    return _proxy_wrapper\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#getting-started-for-local-development","title":"Getting Started for Local Development","text":"<p>We recommend using Tox to setup the development environment. This will create a new virtual environment with all of the required packages installed and ProxyStore installed in editable mode with the necessary extras options.</p> <pre><code>$ git clone https://github.com/proxystore/extensions\n$ cd extensions\n$ tox --devenv venv -e py311\n$ . venv/bin/activate\n</code></pre> <p>Warning</p> <p>Running Tox in a Conda environment is possible but it may conflict with Tox's ability to find the correct Python versions. E.g., if your Conda environment is Python 3.9, running <code>$ tox -e p38</code> may still use Python 3.9.</p> <p>To install manually: <pre><code>$ git clone https://github.com/proxystore/extensions\n$ cd extensions\n$ python -m venv venv\n$ . venv/bin/activate\n$ pip install -e .[dev,docs]\n</code></pre></p>"},{"location":"contributing/#continuous-integration","title":"Continuous Integration","text":"<p>ProxyStore uses pre-commit and Tox for continuous integration (test, linting, etc.).</p>"},{"location":"contributing/#linting-and-type-checking-pre-commit","title":"Linting and Type Checking (pre-commit)","text":"<p>To use pre-commit, install the hook and then run against files.</p> <pre><code>$ pre-commit install\n$ pre-commit run --all-files\n</code></pre>"},{"location":"contributing/#tests-tox","title":"Tests (tox)","text":"<p>The entire CI workflow can be run with <code>$ tox</code>. This will test against multiple versions of Python and can be slow.</p> <p>Module-level unit-test are located in the <code>tests/</code> directory and its structure is intended to match that of <code>proxystore_ex/</code>. E.g. the tests for <code>proxystore_ex/x/y.py</code> are located in <code>tests/x/y_test.py</code>; however, additional test files can be added as needed. Tests should be narrowly focused and target a single aspect of the code's functionality, tests should not test internal implementation details of the code, and tests should not be dependent on the order in which they are run.</p> <p>Code that is useful for building tests but is not a test itself belongs in the <code>testing/</code> directory.</p> <pre><code># Run all tests in tests/\n$ tox -e py311\n# Run a specific test\n$ tox -e py311 -- tests/x/y_test.py::test_z\n</code></pre>"},{"location":"contributing/#tests-docker","title":"Tests (docker)","text":"<p>The test suite mocks certain third-party programs that cannot be installed via pip (e.g., Margo, UCX, Redis). For Margo and UCX, a Docker image is provided at proxystore/images with the software pre-built and Python installed. The tox environments <code>py{version}-dim</code> can be run in the container to validate changes against the un-mocked software.</p> <pre><code>$ docker pull ghcr.io/proxystore/proxystore-dim:nightly\n# Be sure to change the path to your proxystore repo directory\n$ docker run --rm -it --network host -v /path/to/proxystore:/proxystore ghcr.io/proxystore/proxystore-dim:nightly\n# Inside container\n$ tox -e py311-dim\n</code></pre>"},{"location":"contributing/#docs","title":"Docs","text":"<p>If code changes require an update to the documentation (e.g., for function signature changes, new modules, etc.), the documentation can be built using MKDocs.</p> <pre><code># Manually\n$ pip install -e .[docs]\n$ mkdocs build --strict  # Build only to site/index.html\n$ mkdocs serve           # Serve locally\n\n# With tox (will only build, does not serve)\n$ tox -e docs\n</code></pre> <p>Docstrings are automatically generated, but it is recommended to check the generated docstrings to make sure details/links/etc. are correct.</p>"},{"location":"contributing/issues-pull-requests/","title":"Issues and Pull Requests","text":""},{"location":"contributing/issues-pull-requests/#issues","title":"Issues","text":"<p>Issue Tracker</p> <p>We use GitHub issues to report problems, request and track changes, and discuss future ideas. If you open an issue for a specific problem, please follow the template guides.</p>"},{"location":"contributing/issues-pull-requests/#pull-requests","title":"Pull Requests","text":"<p>We use the standard GitHub contribution cycle where all contributions are made via pull requests (including code owners!).</p> <ol> <li>Fork the repository and clone to your local machine.</li> <li> <p>Create local changes.</p> <ul> <li>Changes should conform to the style and testing guidelines, referenced   above.</li> <li>Preferred commit message format (source):<ul> <li>separate subject from body with a blank line,</li> <li>limit subject line to 50 characters,</li> <li>capitalize first word of subject line,</li> <li>do not end the subject line with a period,</li> <li>use the imperative mood for subject lines,</li> <li>include related issue numbers at end of subject line,</li> <li>wrap body at 72 characters, and</li> <li>use the body to explain what/why rather than how.</li> <li>Example: <code>Fix concurrency bug in Store (#42)</code></li> </ul> </li> </ul> </li> <li> <p>Push commits to your fork.</p> <ul> <li>Please squash commits fixing mistakes to keep the git history clean.   For example, if commit \"b\" follows commit \"a\" and only fixes a small typo   from \"a\", please squash \"a\" and \"b\" into a single, correct commit.   This keeps the commit history readable and easier to search through when   debugging (e.g., git blame/bisect).</li> </ul> </li> <li>Open a pull request in this repository.<ul> <li>The pull request should include a description of the motivation for the   PR and included changes. A PR template is provided to guide this process.</li> </ul> </li> </ol>"},{"location":"contributing/releases/","title":"Releases","text":""},{"location":"contributing/releases/#release-timeline","title":"Release Timeline","text":"<p>Releases are created on an as-needed basis. Milestones are the Issue Tracker are used to track features to be included in upcoming releases.</p>"},{"location":"contributing/releases/#creating-releases","title":"Creating Releases","text":"<ol> <li>Choose the next version number, referred to as <code>{VERSION}</code> for the    rest of the instructions. ProxyStore versioning follows semver    (<code>major.minor.patch</code>) with optional PEP-440    pre-release/post-release/dev-release segments. Major/minor/patch numbers    start at 0 and pre-release/post-release/dev-release segments start at 1.</li> <li>Update the version in <code>pyproject.toml</code> to <code>{VERSION}</code>.</li> <li>Commit and merge the version updates/changelogs into main.</li> <li>Tag the release commit and push (typically this is the commit updating the    version numbers).    <pre><code>$ git tag -s v{VERSION} -m \"ProxyStore Extensions v{VERSION}\"\n$ git push origin v{VERSION}\n</code></pre>    Note the version number is prepended by \"v\" for the tags so we can    distinguish release tags from non-release tags.</li> <li>Create a new release on GitHub using the tag. The title should be    <code>ProxyStore Extensions v{VERSION}</code>.</li> <li>Official release:<ol> <li>Use the \"Generate release notes\" option and set the previous tag as the previous official release tag. E.g., for <code>v0.4.1</code>, the previous release tag should be <code>v0.4.0</code> and NOT <code>v0.4.1a1</code>.</li> <li>Add an \"Upgrade Steps\" section at the top (see previous releases for examples).</li> <li>Review the generated notes and edit as needed. PRs are organized by tag, but some PRs will be missing tags and need to be moved from the \"Other Changes\" section to the correct section.</li> <li>Select \"Set as the latest release.\"</li> </ol> </li> <li>Unofficial release: (alpha/dev builds)<ol> <li>Do NOT generate release notes. The body can be along the lines of \"Development pre-prelease for <code>V{VERSION}</code>.\"</li> <li>Leave the previous tag as \"auto.\"</li> <li>Select \"Set as a pre-release.\"</li> </ol> </li> </ol>"},{"location":"contributing/style-guide/","title":"Style Guide","text":"<p>See the ProxyStore Style Guide.</p>"},{"location":"guides/","title":"Guides","text":"<ul> <li>DAOS at ALCF</li> <li>Dask with ProxyStore</li> </ul>"},{"location":"guides/daos/","title":"DAOS at ALCF","text":"<p>Last updated 10 October 2023</p> <p>This guide shows you how to use ProxyStore with DAOS at ALCF.</p> <p>Note</p> <p>While some parts of this guide is specific to ALCF, the general steps should apply to any system with a DAOS cluster.</p> <p>The Distributed Asynchronous Object Storage (DAOS) is a distributed object store designed for high-speed non-volatile memory storage like Intel Optane and NVMe. ALCF's Sunspot and Aurora systems have or will have DAOS deployments.</p> <p>ProxyStore Extensions provides support for DAOS via the <code>DAOSConnector</code> which uses PyDAOS internally to connect to a DAOS pool.</p> <p>References:</p> <ul> <li>DAOS v2.4 Documentation</li> <li>PyDAOS Introduction</li> <li>PyDAOS v2.4 Implementation</li> <li>DAOS on ALCF's Sunspot</li> </ul>"},{"location":"guides/daos/#installation","title":"Installation","text":"<p>PyDAOS is automatically installed into your systems Python and does not currently provide any wheels for pip installation. This means that on Sunspot, PyDAOS is only available via the Python 3.6 installation which is older than what ProxyStore is compatible with. To get around this, we will create a newer Python virtual environment and copy the system version into the virtual environment.</p> <pre><code># Load necessary modules on Sunspot\nmodule load daos\nmodule load cray-python\n\n# Create a virtual environment with ProxyStore Extensions installed\npython -m venv venv\n. venv/bin/activate\npip install proxystore-ex\n\n# Copy the system pydaos into our environment\ncp -r /usr/lib64/python3.6/site-packages/pydaos/ $PWD/venv/lib64/python3.9/site-packages/\n\n# Verify that pydaos imports\npython -c \"import pydaos\"\n</code></pre>"},{"location":"guides/daos/#create-a-daos-pool-and-container","title":"Create a DAOS Pool and Container","text":"<p>PyDAOS requires an existing DAOS pool and container. On Sunspot, a DAOS pool allocation can be requested from ALCF support. Once you have a DAOS pool and its name (for ALCF this will be the name of the allocation you requested it under), you can create a container in the pool. The type must by <code>PYTHON</code> for use with PyDAOS, but the container label can be anything you want.</p> <pre><code>daos container create $POOL_NAME --type=PYTHON --label=demo-container\n</code></pre>"},{"location":"guides/daos/#create-a-connector","title":"Create a Connector","text":"<p>Creating a <code>DAOSConnector</code> is simple.</p> <pre><code>from proxystore_ex.connectors.daos import DAOSConnector\n\nwith DAOSConnector(\n    pool=...,\n    container='demo-container',\n    namespace='proxystore',\n) as connector:\n    key = connector.put(b'data')\n    assert connector.exists(key)\n    assert connector.get(key) == b'data'\n\n    connector.evict(key)\n    assert not connector.exists(key)\n</code></pre> <p>The <code>namespace</code> argument is used as the name for the DAOS dictionary created within the DAOS container that you provided. All operations by the connector will be done within that \"namespace\" or dictionary. This is helpful for preventing ProxyStore from clashing with other operations from other programs on the same container.</p>"},{"location":"guides/daos/#using-with-a-store","title":"Using with a Store","text":"<p>A <code>DAOSConnector</code> can be used to initialize a ProxyStore <code>Store</code>. Learn more about the <code>Store</code> interface in the Get Started guide.</p> <pre><code>from proxystore.store import Store\nfrom proxystore_ex.connectors.daos import DAOSConnector\n\nconnector = DAOSConnector\n    pool=...,\n    container='demo-container',\n    namespace='proxystore',\n)\n\nwith Store('my-store' connector) as store:\n    key = store.put(my_object)\n    assert store.get(my_object)\n\n    p = store.proxy(my_object)\n\n    assert isinstance(p, type(my_object))\n</code></pre>"},{"location":"guides/dask-distributed/","title":"Dask with ProxyStore","text":"<p>Last updated 25 April 2024</p> <p>The Dask with ProxyStore guide has moved to https://docs.proxystore.dev/latest/guides/dask-distributed/.</p> <p>To learn more about using the custom Dask client provided by this package, read the <code>proxystore_ex.plugins.distributed</code> API docs.</p>"}]}